{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_router import Route\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from semantic_router import RouteLayer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_dict = {\n",
    "    \"creating_flashcards\": \"The user wants to generate flashcards based on provided information\",\n",
    "    \"motivational_support\": \"The user needs motivational support to continue on with their studies\",\n",
    "    \"recommendations_and_learning_resources\": \"the user needs some recomendations of resources for their studying\",\n",
    "    \"update_user_info\": \"The user wants to update/read/delete their personal information\",\n",
    "    \"aurora_related\": \"The user wants to know more about Aurora, the Chatbot\",\n",
    "    \"study_planning\": \"The user wants to have a study plan based on their preferences\",\n",
    "    \"generate_citation\": \"The user want to have a citation to a givent text from possible documents\",\n",
    "    \"summarize_file\": \"The user wants to recieve the summarised text from the provided file\",\n",
    "    \"creating_quizzes\": \"The user wants to receive a quizz based on provided information\",\n",
    "    \"send_email\": \"The user wants to send an email to someone\",\n",
    "    \"None\": \"The users talks about unrelated topics\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import and split\n",
    "df_loaded = pd.read_json(\"files/intentions.json\") \n",
    "X = df_loaded[['Id','Message']]\n",
    "y = df_loaded['Intention'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0, stratify=y)\n",
    "# Replace \"None\" with None\n",
    "y_train = [None if i == \"None\" else i for i in y_train]\n",
    "y_test = [None if i == \"None\" else i for i in y_test]\n",
    "# Set the column Id as the index\n",
    "X_train.set_index('Id', inplace=True)\n",
    "X_test.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_dict = {}\n",
    "for message, label in zip(X_train[\"Message\"], y_train):\n",
    "    if label is not None and label in messages_dict.values():\n",
    "        messages_dict[label].append(message)\n",
    "    elif label is not None:\n",
    "        messages_dict[label] = [message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = []\n",
    "for label, message_list in zip(messages_dict.keys(),\n",
    "                               messages_dict.values()):\n",
    "    routes.append(\n",
    "        Route(\n",
    "            name=label,\n",
    "            description=description_dict[label], \n",
    "            utterances=message_list\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intention 'motivational_support': 75.00% (8 examples)\n",
      "Intention 'update_user_info': 85.71% (7 examples)\n",
      "Intention 'recommendations_and_learning_resources': 85.71% (7 examples)\n",
      "Intention 'study_planning': 75.00% (8 examples)\n",
      "Intention 'generate_citation': 100.00% (7 examples)\n",
      "Intention 'send_email': 100.00% (8 examples)\n",
      "Intention 'None': 100.00% (8 examples)\n",
      "Intention 'aurora_related': 100.00% (8 examples)\n",
      "Intention 'creating_quizzes': 85.71% (7 examples)\n",
      "Intention 'summarize_file': 71.43% (7 examples)\n",
      "Intention 'creating_flashcards': 87.50% (8 examples)\n",
      "\n",
      "Overall Accuracy: 87.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = OpenAIEncoder()\n",
    "oa_rl = RouteLayer(encoder=encoder, routes=routes, aggregation=\"mean\")\n",
    "\n",
    "# Initialize a dictionary to store the accuracy for each intention\n",
    "intention_accuracy = {}\n",
    "intention_counts = {}\n",
    "\n",
    "# Total correct predictions and examples for overall accuracy\n",
    "total_correct = 0\n",
    "total_examples = 0\n",
    "\n",
    "# Iterate through each unique intention in y_test\n",
    "for intention in set(y_test):\n",
    "    # Filter messages and labels for the current intention\n",
    "    indices = [i for i, y in enumerate(y_test) if y == intention]\n",
    "    X_subset = [X_test[\"Message\"].iloc[i] for i in indices]\n",
    "    y_subset = [y_test[i] for i in indices]\n",
    "    \n",
    "    # Evaluate the accuracy for the current intention\n",
    "    if len(y_subset) > 0:\n",
    "        accuracy = oa_rl.evaluate(X=X_subset, y=y_subset)\n",
    "        intention_accuracy[intention] = accuracy\n",
    "        intention_counts[intention] = len(y_subset)\n",
    "        \n",
    "        # Update overall correct predictions and examples\n",
    "        total_correct += int(accuracy * len(y_subset))\n",
    "        total_examples += len(y_subset)\n",
    "    else:\n",
    "        intention_accuracy[intention] = None\n",
    "        intention_counts[intention] = 0\n",
    "\n",
    "# Print accuracy per intention\n",
    "for intention, accuracy in intention_accuracy.items():\n",
    "    if accuracy is not None:\n",
    "        print(f\"Intention '{intention}': {accuracy * 100:.2f}% ({intention_counts[intention]} examples)\")\n",
    "    else:\n",
    "        print(f\"Intention '{intention}': No examples in the test set.\")\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "overall_accuracy = total_correct / total_examples if total_examples > 0 else 0\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-04 17:42:58 INFO semantic_router.utils.logger Saving route config to files/layer.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "oa_rl.to_json(\"files/layer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] \n",
      "\n",
      "None \n",
      "\n",
      "New route thresholds: {'motivational_support': 0.3, 'update_user_info': 0.3, 'recommendations_and_learning_resources': 0.3, 'creating_quizzes': 0.3, 'send_email': 0.3, 'generate_citation': 0.3, 'creating_flashcards': 0.3, 'aurora_related': 0.3, 'study_planning': 0.3, 'summarize_file': 0.3} \n",
      "\n",
      "Id: 277\n",
      "Message: Can you summarize this article on programming best practices?\n",
      "True Route: summarize_file, Predicted Route: aurora_related\n",
      "\n",
      "Id: 367\n",
      "Message: I don’t feel motivated at all.\n",
      "True Route: motivational_support, Predicted Route: None\n",
      "\n",
      "Id: 352\n",
      "Message: I am so lost on Text Mining.\n",
      "True Route: motivational_support, Predicted Route: generate_citation\n",
      "\n",
      "Id: 144\n",
      "Message: Prepare flashcards on computer vision concepts.\n",
      "True Route: creating_flashcards, Predicted Route: recommendations_and_learning_resources\n",
      "\n",
      "Id: 534\n",
      "Message: Can you create a plan to prepare for my Python programming test?\n",
      "True Route: study_planning, Predicted Route: creating_quizzes\n",
      "\n",
      "Id: 401\n",
      "Message: What are the recommended courses based on my academic records?\n",
      "True Route: recommendations_and_learning_resources, Predicted Route: None\n",
      "\n",
      "Id: 65\n",
      "Message: Create a quiz based on my Biology documents.\n",
      "True Route: creating_quizzes, Predicted Route: study_planning\n",
      "\n",
      "Id: 508\n",
      "Message: Help me create a study plan for my Machine Learning project.\n",
      "True Route: study_planning, Predicted Route: summarize_file\n",
      "\n",
      "Id: 205\n",
      "Message: I want my goal of minutes to be 30 per day.\n",
      "True Route: update_user_info, Predicted Route: None\n",
      "\n",
      "Id: 291\n",
      "Message: Can you summarize the text mining book chapter?\n",
      "True Route: summarize_file, Predicted Route: aurora_related\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# those all are check\n",
    "print(oa_rl.retrieve_multiple_routes(\"Я люблю сосиски і квізи\"), \"\\n\")\n",
    "print(oa_rl(\"Я люблю сосиски і квізи\").name, \"\\n\")\n",
    "route_thresholds = oa_rl.get_thresholds()\n",
    "print(\"New route thresholds:\", route_thresholds, \"\\n\")\n",
    "\n",
    "for (index, row), label in zip(X_test.iterrows(), y_test):\n",
    "    message = row[\"Message\"]\n",
    "    prediction = oa_rl(message)\n",
    "\n",
    "    if prediction.name == label:\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Id: {index}\")\n",
    "        print(f\"Message: {message}\")\n",
    "        print(f\"True Route: {label}, Predicted Route: {prediction.name}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_group7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
